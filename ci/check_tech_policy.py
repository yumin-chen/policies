import json
import toml
import xml.etree.ElementTree as ET
import sys
import subprocess
from pathlib import Path
from dataclasses import dataclass
from typing import List, Dict, Tuple, Optional
from datetime import datetime
import re
import unittest
from unittest.mock import patch, mock_open

@dataclass
class Dependency:
    """Unified dependency representation across ecosystems"""
    name: str
    version: str
    ecosystem: str
    license: str = "unknown"
    implementations: int = 1
    vendor_specific: bool = False
    documentation: bool = False
    migration_path: bool = False

    def __hash__(self):
        return hash((self.name, self.ecosystem))

class ExceptionManager:
    """Loads and checks for approved policy exceptions"""

    def __init__(self, file_path="policy_exceptions.json"):
        self.exceptions = self._load_exceptions(file_path)

    def _load_exceptions(self, file_path: str) -> List[Dict]:
        """Loads and parses the exceptions file"""
        exceptions = []
        try:
            with open(file_path, 'r') as f:
                data = json.load(f)
                for exc in data.get("exceptions", []):
                    try:
                        exc["expires_on"] = datetime.strptime(exc["expires_on"], "%Y-%m-%d")
                        exceptions.append(exc)
                    except (ValueError, TypeError):
                        print(f"âš  Warning: Skipping exception with invalid date: {exc}")
        except FileNotFoundError:
            pass # No exceptions file is fine
        except Exception as e:
            print(f"âš  Warning: Failed to load or parse exceptions file: {e}")
        return exceptions

    def is_exception(self, dep: Dependency) -> Optional[Dict]:
        """Checks if a dependency is covered by a valid, unexpired exception"""
        today = datetime.now()
        for exc in self.exceptions:
            if (dep.name == exc["dependency"] and
                dep.ecosystem == exc["ecosystem"] and
                today <= exc["expires_on"]):
                return exc
        return None

class LicenseFetcher:
    """Fetches real license data using external tools"""
    @staticmethod
    def fetch_python_licenses() -> Dict[str, str]:
        """Runs pip-licenses to get licenses for installed Python packages"""
        licenses = {}
        print("ðŸ” Fetching Python licenses using pip-licenses...")
        try:
            result = subprocess.run(
                ["pip-licenses", "--format=json"],
                capture_output=True, text=True, check=True
            )
            data = json.loads(result.stdout)
            for item in data:
                licenses[item['Name'].lower()] = item['License']
            print(f"âœ… Found {len(licenses)} Python licenses.")
        except (subprocess.CalledProcessError, FileNotFoundError, json.JSONDecodeError) as e:
            print(f"âš  Warning: Failed to fetch Python licenses: {e}")
        return licenses

    @staticmethod
    def fetch_nodejs_licenses() -> Dict[str, str]:
        """Runs license-checker for Node.js packages"""
        licenses = {}
        print("ðŸ” Fetching Node.js licenses using license-checker...")
        try:
            result = subprocess.run(
                ["./node_modules/.bin/license-checker", "--json"],
                capture_output=True, text=True, check=True
            )
            data = json.loads(result.stdout)
            for name_version, info in data.items():
                name = name_version.rsplit('@', 1)[0]
                licenses[name] = info.get('licenses', 'unknown')
            print(f"âœ… Found {len(licenses)} Node.js licenses.")
        except (subprocess.CalledProcessError, FileNotFoundError, json.JSONDecodeError) as e:
            print(f"âš  Warning: Failed to fetch Node.js licenses: {e}")
        return licenses

    @staticmethod
    def fetch_java_licenses() -> Dict[str, str]:
        """Parses the license report generated by the license-maven-plugin"""
        licenses = {}
        print("ðŸ” Parsing Java license report...")
        report_path = Path("target/generated-resources/licenses.xml")
        if not report_path.exists():
            print("âš  Warning: Java license report (licenses.xml) not found.")
            return licenses
        try:
            tree = ET.parse(report_path)
            root = tree.getroot()
            # No namespace needed for this generated file
            for dep_node in root.findall('.//dependency'):
                group_id = dep_node.find('groupId').text
                artifact_id = dep_node.find('artifactId').text
                license_node = dep_node.find('.//license/name')
                license_name = license_node.text if license_node is not None else "unknown"
                full_name = f"{group_id}:{artifact_id}"
                licenses[full_name] = license_name
            print(f"âœ… Parsed {len(licenses)} Java licenses from report.")
        except ET.ParseError as e:
            print(f"âš  Warning: Failed to parse Java license report: {e}")
        return licenses

class DependencyParser:
    """Parse dependencies and enrich with real and supplemental data"""

    OSI_APPROVED = [
        "MIT", "Apache-2.0", "Apache License 2.0", "The Apache Software License, Version 2.0",
        "BSD-3-Clause", "BSD-2-Clause",
        "GPL-3.0", "GPL-3.0-or-later", "LGPL-3.0",
        "ISC", "MPL-2.0", "CDDL-1.0", "EPL-1.0"
    ]

    @staticmethod
    def parse_python_dependencies() -> List[Dependency]:
        deps = []
        pyproject_path = Path("pyproject.toml")
        if pyproject_path.exists():
            try:
                config = toml.load(pyproject_path)
                py_deps = config.get('tool', {}).get('poetry', {}).get('dependencies', {})
                for name, spec in py_deps.items():
                    if name.lower() == "python": continue
                    version = spec if isinstance(spec, str) else spec.get("version", "*")
                    deps.append(Dependency(name=name.lower(), version=version, ecosystem="python"))
            except Exception as e:
                print(f"âš  Warning: Failed to parse pyproject.toml: {e}")
        return deps

    @staticmethod
    def parse_nodejs_dependencies() -> List[Dependency]:
        deps = []
        package_path = Path("package.json")
        if not package_path.exists(): return deps
        try:
            with open(package_path, 'r') as f:
                package_json = json.load(f)
            for name, version in package_json.get('dependencies', {}).items():
                deps.append(Dependency(name=name, version=version, ecosystem="nodejs"))
            for name, version in package_json.get('devDependencies', {}).items():
                deps.append(Dependency(name=name, version=version, ecosystem="nodejs"))
        except Exception as e:
            print(f"âš  Warning: Failed to parse package.json: {e}")
        return deps

    @staticmethod
    def parse_java_dependencies() -> List[Dependency]:
        deps = []
        pom_path = Path("pom.xml")
        if not pom_path.exists(): return deps
        try:
            tree = ET.parse(pom_path)
            root = tree.getroot()
            namespace = root.tag.split('}')[0][1:] if '}' in root.tag else ''
            ns_map = {'m': namespace} if namespace else {}

            def find_all_in_ns(element, path):
                return element.findall(path, ns_map) if namespace else element.findall(path.replace('m:', ''))

            def find_in_ns(element, path):
                return element.find(path, ns_map) if namespace else element.find(path.replace('m:', ''))

            for dep_node in find_all_in_ns(root, './/m:dependency'):
                scope = find_in_ns(dep_node, 'm:scope')
                if scope is not None and scope.text == 'test': continue

                group_id = (find_in_ns(dep_node, 'm:groupId') or ET.Element("")).text
                artifact_id = (find_in_ns(dep_node, 'm:artifactId') or ET.Element("")).text
                version = (find_in_ns(dep_node, 'm:version') or ET.Element("")).text or "*"

                if artifact_id:
                    full_name = f"{group_id}:{artifact_id}"
                    deps.append(Dependency(name=full_name, version=version, ecosystem="java"))
        except Exception as e:
            print(f"âš  Warning: Failed to parse pom.xml: {e}")
        return deps

    @staticmethod
    def load_supplemental_metadata() -> Dict:
        metadata_path = Path("ci/dependency_metadata.json")
        if not metadata_path.exists(): return {}
        try:
            with open(metadata_path, 'r') as f:
                return json.load(f)
        except json.JSONDecodeError:
            return {}

    @staticmethod
    def load_all_dependencies() -> List[Dependency]:
        # Fetch real license data
        python_licenses = LicenseFetcher.fetch_python_licenses()
        nodejs_licenses = LicenseFetcher.fetch_nodejs_licenses()
        java_licenses = LicenseFetcher.fetch_java_licenses()

        # Parse dependency lists from manifests
        all_deps = []
        all_deps.extend(DependencyParser.parse_python_dependencies())
        all_deps.extend(DependencyParser.parse_nodejs_dependencies())
        all_deps.extend(DependencyParser.parse_java_dependencies())

        # Load supplemental (manual) metadata
        supplemental_meta = DependencyParser.load_supplemental_metadata()

        # Enrich dependencies with fetched and supplemental data
        for dep in all_deps:
            # Set real license data
            if dep.ecosystem == "python":
                dep.license = python_licenses.get(dep.name, "unknown")
            elif dep.ecosystem == "nodejs":
                dep.license = nodejs_licenses.get(dep.name, "unknown")
            elif dep.ecosystem == "java":
                dep.license = java_licenses.get(dep.name, "unknown")


            # Apply supplemental metadata
            eco_meta = supplemental_meta.get(dep.ecosystem, {})
            dep_meta = eco_meta.get(dep.name, {})
            dep.implementations = dep_meta.get("implementations", 1)
            dep.vendor_specific = dep_meta.get("vendor_specific", False)
            dep.documentation = dep_meta.get("documentation", False)
            dep.migration_path = dep_meta.get("migration_path", False)

        # Deduplicate
        seen = set()
        unique_deps = [d for d in all_deps if (d.name, d.ecosystem) not in seen and not seen.add((d.name, d.ecosystem))]
        return unique_deps

class PolicyEnforcer:
    @staticmethod
    def check_license(dep: Dependency) -> Tuple[bool, str]:
        if dep.license == "unknown":
            return False, f"License unknown for {dep.name}"
        if dep.license not in DependencyParser.OSI_APPROVED:
            return False, f"{dep.name}: License '{dep.license}' not OSI-approved"
        return True, f"âœ“ {dep.name}: License compliant"

    @staticmethod
    def check_implementations(dep: Dependency) -> Tuple[bool, str]:
        if dep.implementations < 2:
            return False, f"{dep.name}: Only {dep.implementations} implementation(s) found (need â‰¥2)"
        return True, f"âœ“ {dep.name}: Multiple implementations verified"

    @staticmethod
    def check_vendor_lock_in(dep: Dependency) -> Tuple[bool, str]:
        if not dep.vendor_specific:
            return True, f"âœ“ {dep.name}: Not vendor-specific"
        if not (dep.documentation and dep.migration_path):
            missing = [p for p, v in [("documentation", dep.documentation), ("migration path", dep.migration_path)] if not v]
            return False, f"{dep.name}: Vendor-specific but missing {', '.join(missing)}"
        return True, f"âœ“ {dep.name}: Vendor-specific with migration path & docs"

    @staticmethod
    def check_ecosystem_diversity(deps: List[Dependency]) -> Tuple[bool, str]:
        eco_counts = {}
        for dep in deps: eco_counts[dep.ecosystem] = eco_counts.get(dep.ecosystem, 0) + 1
        total = len(deps)
        warnings = [f"{eco}: {(count/total*100):.0f}%" for eco, count in eco_counts.items() if (count/total) > 0.7]
        if warnings:
            return False, f"Ecosystem concentration risk: {', '.join(warnings)}"
        return True, "âœ“ Ecosystem diversity acceptable"

class Report:
    def __init__(self):
        self.violations = []
        self.warnings = []
        self.passed = []

    def add(self, passed: bool, msg: str, is_violation: bool):
        if passed: self.passed.append(msg)
        elif is_violation: self.violations.append(msg)
        else: self.warnings.append(msg)

    def add_exception(self, dep: Dependency, exc: Dict):
        """Adds a special message for an approved exception"""
        self.passed.append(f"âœ“ {dep.name}: Exception approved (Reason: {exc['reason']})")

    def print_report(self):
        print("\n" + "="*70 + "\nTECHNOLOGY POLICY COMPLIANCE REPORT\n" + "="*70 + "\n")
        if self.passed: print(f"âœ… PASSED CHECKS ({len(self.passed)} total)\n")
        if self.warnings:
            print("âš  WARNINGS:")
            for msg in self.warnings: print(f"   {msg}")
            print()
        if self.violations:
            print("âŒ VIOLATIONS (CI WILL FAIL):")
            for msg in self.violations: print(f"   {msg}")
            print()
            return False
        print("âœ… ALL COMPLIANCE CHECKS PASSED\n")
        return True

def run_policy_checks():
    print("ðŸ” Scanning and verifying dependencies...\n")

    # Load dependencies and exceptions
    deps = DependencyParser.load_all_dependencies()
    exception_manager = ExceptionManager()

    if not deps:
        print("âš  No dependencies found. Skipping policy checks.")
        sys.exit(0)

    print(f"Found {len(deps)} unique dependencies.\n")

    report = Report()
    for dep in deps:
        exception = exception_manager.is_exception(dep)
        if exception:
            report.add_exception(dep, exception)
            continue # Skip normal checks if there's a valid exception

        passed, msg = PolicyEnforcer.check_license(dep)
        report.add(passed, msg, is_violation=True)

        passed, msg = PolicyEnforcer.check_implementations(dep)
        report.add(passed, msg, is_violation=False) # This is a warning

        passed, msg = PolicyEnforcer.check_vendor_lock_in(dep)
        report.add(passed, msg, is_violation=True)

    passed, msg = PolicyEnforcer.check_ecosystem_diversity(deps)
    report.add(passed, msg, is_violation=False) # This is a warning

    success = report.print_report()
    sys.exit(0 if success else 1)

class TestPolicyScript(unittest.TestCase):

    @patch('__main__.DependencyParser.parse_python_dependencies')
    def test_python_parser(self, mock_parser):
        mock_parser.return_value = [Dependency('requests', '1.0', 'python')]
        deps = DependencyParser.parse_python_dependencies()
        self.assertEqual(len(deps), 1)
        self.assertEqual(deps[0].name, 'requests')

    def test_license_checker(self):
        compliant_dep = Dependency('test', '1.0', 'python', license='MIT')
        non_compliant_dep = Dependency('test', '1.0', 'python', license='Proprietary')
        self.assertTrue(PolicyEnforcer.check_license(compliant_dep)[0])
        self.assertFalse(PolicyEnforcer.check_license(non_compliant_dep)[0])

    def test_exception_logic(self):
        manager = ExceptionManager()
        manager.exceptions = [{
            "dependency": "legacy-lib",
            "ecosystem": "python",
            "expires_on": datetime(2099, 12, 31)
        }]
        dep = Dependency(name='legacy-lib', version='1.0', ecosystem='python')
        self.assertIsNotNone(manager.is_exception(dep))

        expired_dep = Dependency(name='old-lib', version='1.0', ecosystem='python')
        manager.exceptions = [{
            "dependency": "old-lib",
            "ecosystem": "python",
            "expires_on": datetime(2020, 1, 1)
        }]
        self.assertIsNone(manager.is_exception(expired_dep))

def run_tests():
    # This is a simple way to run tests from the script itself
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(TestPolicyScript))
    runner = unittest.TextTestRunner()
    result = runner.run(suite)
    sys.exit(not result.wasSuccessful())

if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] == 'test':
        run_tests()
    else:
        run_policy_checks()
